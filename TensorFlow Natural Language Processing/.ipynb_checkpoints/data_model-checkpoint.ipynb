{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow used for\n",
    "## Natural Language Processing \n",
    "\n",
    "code source: [Magnus Erik Hvass Pedersen](http://www.hvass-labs.org/)\n",
    "/ [GitHub](https://github.com/Hvass-Labs/TensorFlow-Tutorials) / [Videos on YouTube](https://www.youtube.com/playlist?list=PL9Hr9sNUjfsmEu1ZniY0XpHSzl5uihcXZ)  \n",
    "with modifications from [Tensorflow tutorials](https://www.tensorflow.org/tutorials) at [Tensorflow.org](https://www.tensorflow.org/tutorials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-11-15</td>\n",
       "      <td>&lt;JoeBiden&gt;</td>\n",
       "      <td>congratulations to nasa and spacex on today's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-11-14</td>\n",
       "      <td>&lt;JoeBiden&gt;</td>\n",
       "      <td>to the millions of hindus, jains, sikhs, and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-11-13</td>\n",
       "      <td>&lt;JoeBiden&gt;</td>\n",
       "      <td>i am the president-elect, but will not be pre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        name                                              tweet\n",
       "0  2020-11-15  <JoeBiden>   congratulations to nasa and spacex on today's...\n",
       "1  2020-11-14  <JoeBiden>   to the millions of hindus, jains, sikhs, and ...\n",
       "2  2020-11-13  <JoeBiden>   i am the president-elect, but will not be pre..."
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data from csv\n",
    "politics_tweet_df = pd.read_csv('../data/politics_tweet.csv')\n",
    "politics_tweet_df= politics_tweet_df.drop(['Unnamed: 0'], axis=1)\n",
    "politics_tweet_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date     3032\n",
       "name     3032\n",
       "tweet    3032\n",
       "dtype: int64"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count data for JoeBiden\n",
    "politics_tweet_df[politics_tweet_df['name']=='<JoeBiden>'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count data for realDonaldTrump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date     4019\n",
       "name     4019\n",
       "tweet    4019\n",
       "dtype: int64"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politics_tweet_df[politics_tweet_df['name']=='<realDonaldTrump>'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date     515\n",
       "name     515\n",
       "tweet    515\n",
       "dtype: int64"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politics_tweet_df[politics_tweet_df['name']=='<senatemajldr>'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date     1005\n",
       "name     1005\n",
       "tweet    1005\n",
       "dtype: int64"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politics_tweet_df[politics_tweet_df['name']=='<SpeakerPelosi>'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-11-15</td>\n",
       "      <td>&lt;JoeBiden&gt;</td>\n",
       "      <td>congratulations to nasa and spacex on today's...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-11-14</td>\n",
       "      <td>&lt;JoeBiden&gt;</td>\n",
       "      <td>to the millions of hindus, jains, sikhs, and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-11-13</td>\n",
       "      <td>&lt;JoeBiden&gt;</td>\n",
       "      <td>i am the president-elect, but will not be pre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-11-13</td>\n",
       "      <td>&lt;JoeBiden&gt;</td>\n",
       "      <td>i am alarmed by the surge in reported covid-1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-11-13</td>\n",
       "      <td>&lt;JoeBiden&gt;</td>\n",
       "      <td>as the remnants of tropical storm eta continu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8566</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>&lt;senatemajldr&gt;</td>\n",
       "      <td>for too long, this evil man operated without ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8567</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>&lt;senatemajldr&gt;</td>\n",
       "      <td>soleimani made it his life’s work to take the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8568</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>&lt;senatemajldr&gt;</td>\n",
       "      <td>this morning, iran’s master terrorist is dead...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8569</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>&lt;senatemajldr&gt;</td>\n",
       "      <td>senators do not cease to be senators just bec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8570</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>&lt;senatemajldr&gt;</td>\n",
       "      <td>the senate will soon have to address some of ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8571 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date            name  \\\n",
       "0     2020-11-15      <JoeBiden>   \n",
       "1     2020-11-14      <JoeBiden>   \n",
       "2     2020-11-13      <JoeBiden>   \n",
       "3     2020-11-13      <JoeBiden>   \n",
       "4     2020-11-13      <JoeBiden>   \n",
       "...          ...             ...   \n",
       "8566  2020-01-03  <senatemajldr>   \n",
       "8567  2020-01-03  <senatemajldr>   \n",
       "8568  2020-01-03  <senatemajldr>   \n",
       "8569  2020-01-03  <senatemajldr>   \n",
       "8570  2020-01-03  <senatemajldr>   \n",
       "\n",
       "                                                  tweet  label  \n",
       "0      congratulations to nasa and spacex on today's...      1  \n",
       "1      to the millions of hindus, jains, sikhs, and ...      1  \n",
       "2      i am the president-elect, but will not be pre...      1  \n",
       "3      i am alarmed by the surge in reported covid-1...      1  \n",
       "4      as the remnants of tropical storm eta continu...      1  \n",
       "...                                                 ...    ...  \n",
       "8566   for too long, this evil man operated without ...      0  \n",
       "8567   soleimani made it his life’s work to take the...      0  \n",
       "8568   this morning, iran’s master terrorist is dead...      0  \n",
       "8569   senators do not cease to be senators just bec...      0  \n",
       "8570   the senate will soon have to address some of ...      0  \n",
       "\n",
       "[8571 rows x 4 columns]"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#label the data\n",
    "def func(x):\n",
    "    if x=='<realDonaldTrump>':\n",
    "        return 0\n",
    "    elif x=='<JoeBiden>':\n",
    "        return 1\n",
    "    elif x=='<SpeakerPelosi>':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "politics_tweet_df['label'] = politics_tweet_df['name'].apply(func)\n",
    "politics_tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8571,) (8571,)\n"
     ]
    }
   ],
   "source": [
    "y = politics_tweet_df[\"label\"]\n",
    "X = politics_tweet_df[\"tweet\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test_split to create training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tf.keras.models import Sequential  # This does not work!\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, GRU, Embedding\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer\n",
    "\n",
    "A neural network cannot work directly on text-strings so we must convert it somehow. There are two steps in this conversion, the first step is called the \"tokenizer\" which converts words to integers and is done on the data-set before it is input to the neural network. The second step is an integrated part of the neural network itself and is called the \"embedding\"-layer, which is described further below.\n",
    "\n",
    "We may instruct the tokenizer to only use e.g. the 10000 most popular words from the data-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 10000\n",
    "tokenizer = Tokenizer(num_words=num_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tokenizer can then be \"fitted\" to the data-set. This scans through all the text and strips it from unwanted characters such as punctuation, and also converts it to lower-case characters. The tokenizer then builds a vocabulary of all unique words along with various data-structures for accessing the data.\n",
    "\n",
    "Note that we fit the tokenizer on the entire data-set so it gathers words from both the training- and test-data. This is OK as we are merely building a vocabulary and want it to be as complete as possible. The actual neural network will of course only be trained on the training-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 430 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer.fit_on_texts(X.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then inspect the vocabulary that has been gathered by the tokenizer. This is ordered by the number of occurrences of the words in the data-set. These integer-numbers are called word indices or \"tokens\" because they uniquely identify each word in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'to': 2,\n",
       " 'and': 3,\n",
       " 'of': 4,\n",
       " 'a': 5,\n",
       " 'in': 6,\n",
       " 'is': 7,\n",
       " 'for': 8,\n",
       " 'we': 9,\n",
       " 'our': 10,\n",
       " 'i': 11,\n",
       " 'this': 12,\n",
       " 'will': 13,\n",
       " 'on': 14,\n",
       " 'that': 15,\n",
       " 'are': 16,\n",
       " 'it': 17,\n",
       " 'you': 18,\n",
       " 'be': 19,\n",
       " 'have': 20,\n",
       " 'with': 21,\n",
       " 'amp': 22,\n",
       " 'president': 23,\n",
       " 'as': 24,\n",
       " '—': 25,\n",
       " 'trump': 26,\n",
       " 'they': 27,\n",
       " 'he': 28,\n",
       " 'has': 29,\n",
       " 'all': 30,\n",
       " 'not': 31,\n",
       " 'my': 32,\n",
       " 'great': 33,\n",
       " 'people': 34,\n",
       " 'your': 35,\n",
       " 'at': 36,\n",
       " 'by': 37,\n",
       " 'who': 38,\n",
       " 'from': 39,\n",
       " 'but': 40,\n",
       " 'was': 41,\n",
       " 'more': 42,\n",
       " 'their': 43,\n",
       " 'american': 44,\n",
       " 'do': 45,\n",
       " 'just': 46,\n",
       " 'now': 47,\n",
       " 'his': 48,\n",
       " 'vote': 49,\n",
       " 'country': 50,\n",
       " 'up': 51,\n",
       " 'need': 52,\n",
       " 'donald': 53,\n",
       " 'if': 54,\n",
       " 'get': 55,\n",
       " 'out': 56,\n",
       " 'today': 57,\n",
       " 'no': 58,\n",
       " 'us': 59,\n",
       " 'one': 60,\n",
       " 'an': 61,\n",
       " 'than': 62,\n",
       " 'can': 63,\n",
       " 'so': 64,\n",
       " 'america': 65,\n",
       " 'what': 66,\n",
       " 'thank': 67,\n",
       " 'make': 68,\n",
       " 'house': 69,\n",
       " 'time': 70,\n",
       " 'or': 71,\n",
       " 'been': 72,\n",
       " 'americans': 73,\n",
       " 'about': 74,\n",
       " 'biden': 75,\n",
       " 'day': 76,\n",
       " 'nation': 77,\n",
       " 'me': 78,\n",
       " 'democrats': 79,\n",
       " 'big': 80,\n",
       " 'new': 81,\n",
       " 'should': 82,\n",
       " 'never': 83,\n",
       " 'years': 84,\n",
       " 'very': 85,\n",
       " 'every': 86,\n",
       " 'together': 87,\n",
       " 'must': 88,\n",
       " 'help': 89,\n",
       " 'going': 90,\n",
       " 'back': 91,\n",
       " 'when': 92,\n",
       " 'senate': 93,\n",
       " 'them': 94,\n",
       " 'like': 95,\n",
       " 'news': 96,\n",
       " 'it’s': 97,\n",
       " 'would': 98,\n",
       " 'health': 99,\n",
       " 'election': 100,\n",
       " 'joe': 101,\n",
       " 'work': 102,\n",
       " 'crisis': 103,\n",
       " 'act': 104,\n",
       " 'covid': 105,\n",
       " 'over': 106,\n",
       " 'many': 107,\n",
       " '”': 108,\n",
       " 'fake': 109,\n",
       " 'care': 110,\n",
       " 'take': 111,\n",
       " 'job': 112,\n",
       " 'even': 113,\n",
       " 'how': 114,\n",
       " 'way': 115,\n",
       " 'states': 116,\n",
       " 'state': 117,\n",
       " 'him': 118,\n",
       " 'want': 119,\n",
       " 'coronavirus': 120,\n",
       " 'there': 121,\n",
       " 'these': 122,\n",
       " 'families': 123,\n",
       " 'win': 124,\n",
       " 'know': 125,\n",
       " 'again': 126,\n",
       " 'white': 127,\n",
       " '19': 128,\n",
       " 'left': 129,\n",
       " 'workers': 130,\n",
       " 'down': 131,\n",
       " 'total': 132,\n",
       " 'am': 133,\n",
       " 'better': 134,\n",
       " 'done': 135,\n",
       " 'because': 136,\n",
       " 'last': 137,\n",
       " 'other': 138,\n",
       " 'world': 139,\n",
       " 'fight': 140,\n",
       " 'jobs': 141,\n",
       " 'were': 142,\n",
       " 'only': 143,\n",
       " 's': 144,\n",
       " 'tune': 145,\n",
       " 'campaign': 146,\n",
       " 'history': 147,\n",
       " 'which': 148,\n",
       " 'u': 149,\n",
       " 'endorsement': 150,\n",
       " 'first': 151,\n",
       " 'working': 152,\n",
       " 'doing': 153,\n",
       " 'against': 154,\n",
       " 'protect': 155,\n",
       " 'good': 156,\n",
       " \"it's\": 157,\n",
       " 'much': 158,\n",
       " 'before': 159,\n",
       " 'most': 160,\n",
       " 'ever': 161,\n",
       " 'complete': 162,\n",
       " 'right': 163,\n",
       " 'see': 164,\n",
       " 'let': 165,\n",
       " 'her': 166,\n",
       " 'lives': 167,\n",
       " 'had': 168,\n",
       " 'support': 169,\n",
       " 'made': 170,\n",
       " 'always': 171,\n",
       " 'economy': 172,\n",
       " 'strong': 173,\n",
       " 'keep': 174,\n",
       " 'law': 175,\n",
       " 'i’m': 176,\n",
       " 'into': 177,\n",
       " 'don’t': 178,\n",
       " 'come': 179,\n",
       " 'nothing': 180,\n",
       " 'administration': 181,\n",
       " 'life': 182,\n",
       " 'across': 183,\n",
       " 'united': 184,\n",
       " 'those': 185,\n",
       " 'after': 186,\n",
       " 'hard': 187,\n",
       " 'any': 188,\n",
       " 'got': 189,\n",
       " 'go': 190,\n",
       " 'everyone': 191,\n",
       " 'national': 192,\n",
       " 'congress': 193,\n",
       " 'court': 194,\n",
       " 'military': 195,\n",
       " 'end': 196,\n",
       " 'amendment': 197,\n",
       " 'stand': 198,\n",
       " 'republicans': 199,\n",
       " 'did': 200,\n",
       " 'said': 201,\n",
       " 'china': 202,\n",
       " 'long': 203,\n",
       " 'here': 204,\n",
       " 'put': 205,\n",
       " 'far': 206,\n",
       " 'through': 207,\n",
       " 'justice': 208,\n",
       " 'federal': 209,\n",
       " 'folks': 210,\n",
       " 'future': 211,\n",
       " 'testing': 212,\n",
       " 'second': 213,\n",
       " 'virus': 214,\n",
       " 'days': 215,\n",
       " 'she': 216,\n",
       " 'also': 217,\n",
       " 'full': 218,\n",
       " 'being': 219,\n",
       " 'well': 220,\n",
       " 'action': 221,\n",
       " 'watch': 222,\n",
       " 'why': 223,\n",
       " 'maga': 224,\n",
       " 'million': 225,\n",
       " 'family': 226,\n",
       " '000': 227,\n",
       " 'democrat': 228,\n",
       " 'ensure': 229,\n",
       " 'another': 230,\n",
       " 'build': 231,\n",
       " 'small': 232,\n",
       " 'pandemic': 233,\n",
       " 'can’t': 234,\n",
       " 'two': 235,\n",
       " 'media': 236,\n",
       " 'bad': 237,\n",
       " 'economic': 238,\n",
       " 'millions': 239,\n",
       " 'we’re': 240,\n",
       " 'safe': 241,\n",
       " \"i'm\": 242,\n",
       " '–': 243,\n",
       " 'best': 244,\n",
       " \"we're\": 245,\n",
       " 'away': 246,\n",
       " 'where': 247,\n",
       " 'honor': 248,\n",
       " 'republican': 249,\n",
       " 'night': 250,\n",
       " 'important': 251,\n",
       " 'year': 252,\n",
       " 'radical': 253,\n",
       " 'continue': 254,\n",
       " 'its': 255,\n",
       " 'public': 256,\n",
       " 'security': 257,\n",
       " 'government': 258,\n",
       " 'proud': 259,\n",
       " 'plan': 260,\n",
       " 'clear': 261,\n",
       " 'sleepy': 262,\n",
       " 'pennsylvania': 263,\n",
       " 'tonight': 264,\n",
       " 'stop': 265,\n",
       " 'hope': 266,\n",
       " 'until': 267,\n",
       " 'political': 268,\n",
       " 'live': 269,\n",
       " 'say': 270,\n",
       " 'november': 271,\n",
       " 'businesses': 272,\n",
       " 'things': 273,\n",
       " 'supreme': 274,\n",
       " 'party': 275,\n",
       " 'join': 276,\n",
       " 'give': 277,\n",
       " 'familiesfirst': 278,\n",
       " 'power': 279,\n",
       " 'everything': 280,\n",
       " 'could': 281,\n",
       " 'response': 282,\n",
       " 'under': 283,\n",
       " 'still': 284,\n",
       " 'look': 285,\n",
       " 'during': 286,\n",
       " 'voting': 287,\n",
       " 'police': 288,\n",
       " 'leadership': 289,\n",
       " 'others': 290,\n",
       " 'violence': 291,\n",
       " 'some': 292,\n",
       " 'incredible': 293,\n",
       " 'money': 294,\n",
       " 'next': 295,\n",
       " 'too': 296,\n",
       " 'ballot': 297,\n",
       " 'women': 298,\n",
       " 'week': 299,\n",
       " 'chip': 300,\n",
       " 'head': 301,\n",
       " 'impeachment': 302,\n",
       " 'early': 303,\n",
       " 'truth': 304,\n",
       " 'crime': 305,\n",
       " 'relief': 306,\n",
       " 'congressman': 307,\n",
       " 'ago': 308,\n",
       " 'order': 309,\n",
       " 'vets': 310,\n",
       " 'bring': 311,\n",
       " 'change': 312,\n",
       " 'lost': 313,\n",
       " 'then': 314,\n",
       " 'washington': 315,\n",
       " 'failed': 316,\n",
       " 'communities': 317,\n",
       " 'four': 318,\n",
       " 'believe': 319,\n",
       " 'real': 320,\n",
       " 'soon': 321,\n",
       " 'deserve': 322,\n",
       " 'thing': 323,\n",
       " 'off': 324,\n",
       " 'corrupt': 325,\n",
       " 'read': 326,\n",
       " 'times': 327,\n",
       " 'john': 328,\n",
       " 'person': 329,\n",
       " 'really': 330,\n",
       " 'moment': 331,\n",
       " 'coming': 332,\n",
       " 'middle': 333,\n",
       " 'without': 334,\n",
       " 'may': 335,\n",
       " 'sure': 336,\n",
       " 'getting': 337,\n",
       " 'discuss': 338,\n",
       " 'i’ll': 339,\n",
       " 'pay': 340,\n",
       " 'open': 341,\n",
       " 'while': 342,\n",
       " 'place': 343,\n",
       " 'community': 344,\n",
       " 'obama': 345,\n",
       " 'trying': 346,\n",
       " 'deal': 347,\n",
       " 'doesn’t': 348,\n",
       " 'rights': 349,\n",
       " '3': 350,\n",
       " 'didn’t': 351,\n",
       " 'ready': 352,\n",
       " 'call': 353,\n",
       " 'promise': 354,\n",
       " 'running': 355,\n",
       " 'carolina': 356,\n",
       " 'lead': 357,\n",
       " 'trump’s': 358,\n",
       " 'love': 359,\n",
       " 'et': 360,\n",
       " 'making': 361,\n",
       " 'yet': 362,\n",
       " 'home': 363,\n",
       " \"can't\": 364,\n",
       " 'few': 365,\n",
       " 'pass': 366,\n",
       " 'statement': 367,\n",
       " 'bill': 368,\n",
       " 'happen': 369,\n",
       " '1': 370,\n",
       " 'beat': 371,\n",
       " 'called': 372,\n",
       " 'senator': 373,\n",
       " 'ballots': 374,\n",
       " 'mike': 375,\n",
       " 'm': 376,\n",
       " 'cannot': 377,\n",
       " 'tax': 378,\n",
       " 'bipartisan': 379,\n",
       " 'around': 380,\n",
       " 'passed': 381,\n",
       " 'taxes': 382,\n",
       " 'mail': 383,\n",
       " 'leader': 384,\n",
       " 'record': 385,\n",
       " \"i'll\": 386,\n",
       " 'months': 387,\n",
       " 'climate': 388,\n",
       " 'forward': 389,\n",
       " 'that’s': 390,\n",
       " 'polls': 391,\n",
       " 'same': 392,\n",
       " 'wants': 393,\n",
       " '10': 394,\n",
       " 'funding': 395,\n",
       " 'since': 396,\n",
       " 'needs': 397,\n",
       " 'he’s': 398,\n",
       " 'michigan': 399,\n",
       " 'york': 400,\n",
       " 'bernie': 401,\n",
       " 'usa': 402,\n",
       " 'own': 403,\n",
       " 'border': 404,\n",
       " 'happy': 405,\n",
       " 'congratulations': 406,\n",
       " 'service': 407,\n",
       " 'high': 408,\n",
       " 'fighting': 409,\n",
       " 'won’t': 410,\n",
       " 'hoax': 411,\n",
       " 'dems': 412,\n",
       " 'does': 413,\n",
       " 'needed': 414,\n",
       " 'run': 415,\n",
       " 'enough': 416,\n",
       " 'florida': 417,\n",
       " 'immediately': 418,\n",
       " 'soul': 419,\n",
       " 'taking': 420,\n",
       " 'p': 421,\n",
       " 'tomorrow': 422,\n",
       " 'leaders': 423,\n",
       " 'numbers': 424,\n",
       " 'use': 425,\n",
       " 'governor': 426,\n",
       " 'democracy': 427,\n",
       " 'already': 428,\n",
       " 'possible': 429,\n",
       " 'russia': 430,\n",
       " 'including': 431,\n",
       " 'think': 432,\n",
       " 'fair': 433,\n",
       " 'dollars': 434,\n",
       " 'single': 435,\n",
       " '2': 436,\n",
       " 'i’ve': 437,\n",
       " 'energy': 438,\n",
       " 'let’s': 439,\n",
       " 'enforcement': 440,\n",
       " 'crazy': 441,\n",
       " 'remember': 442,\n",
       " 'wisconsin': 443,\n",
       " 'cases': 444,\n",
       " 'iowa': 445,\n",
       " 'black': 446,\n",
       " 'wrong': 447,\n",
       " 'pelosi': 448,\n",
       " 'ahead': 449,\n",
       " 'totally': 450,\n",
       " '5': 451,\n",
       " 'north': 452,\n",
       " 'deliver': 453,\n",
       " 'once': 454,\n",
       " \"we've\": 455,\n",
       " '2016': 456,\n",
       " 'both': 457,\n",
       " 'stronger': 458,\n",
       " 'true': 459,\n",
       " 'finally': 460,\n",
       " 'lot': 461,\n",
       " 'fast': 462,\n",
       " 'conference': 463,\n",
       " 'office': 464,\n",
       " 'gun': 465,\n",
       " 'save': 466,\n",
       " 'matter': 467,\n",
       " 'close': 468,\n",
       " 'friends': 469,\n",
       " 'texas': 470,\n",
       " 'fact': 471,\n",
       " 'legislation': 472,\n",
       " 'number': 473,\n",
       " 'america’s': 474,\n",
       " 'chance': 475,\n",
       " 'show': 476,\n",
       " 'worst': 477,\n",
       " 'free': 478,\n",
       " 'price': 479,\n",
       " 'program': 480,\n",
       " 'iran': 481,\n",
       " 'healthcare': 482,\n",
       " 'efforts': 483,\n",
       " 'able': 484,\n",
       " 'battle': 485,\n",
       " 'pm': 486,\n",
       " 'greatest': 487,\n",
       " 'story': 488,\n",
       " 'elected': 489,\n",
       " 'please': 490,\n",
       " 'step': 491,\n",
       " '00': 492,\n",
       " 'war': 493,\n",
       " 'heroesact': 494,\n",
       " 'emergency': 495,\n",
       " 'stay': 496,\n",
       " 'friend': 497,\n",
       " 'three': 498,\n",
       " 'grateful': 499,\n",
       " 'tremendous': 500,\n",
       " 'protections': 501,\n",
       " 'access': 502,\n",
       " 'tough': 503,\n",
       " 'heroes': 504,\n",
       " 'paying': 505,\n",
       " 'anyone': 506,\n",
       " 'between': 507,\n",
       " 'historic': 508,\n",
       " 'wonderful': 509,\n",
       " 'you’re': 510,\n",
       " 'wall': 511,\n",
       " 'protection': 512,\n",
       " 'sign': 513,\n",
       " 'instead': 514,\n",
       " 'man': 515,\n",
       " 'safety': 516,\n",
       " 'morning': 517,\n",
       " 'heard': 518,\n",
       " 'nationwide': 519,\n",
       " 'words': 520,\n",
       " '4': 521,\n",
       " 'defeat': 522,\n",
       " 'social': 523,\n",
       " 'business': 524,\n",
       " 'mini': 525,\n",
       " 'capitol': 526,\n",
       " 'science': 527,\n",
       " 'progress': 528,\n",
       " 'threat': 529,\n",
       " 'trial': 530,\n",
       " 'unemployment': 531,\n",
       " 'looking': 532,\n",
       " 'general': 533,\n",
       " 'children': 534,\n",
       " 'cut': 535,\n",
       " 'press': 536,\n",
       " 'send': 537,\n",
       " 'face': 538,\n",
       " 'schools': 539,\n",
       " 'race': 540,\n",
       " '30': 541,\n",
       " 'entire': 542,\n",
       " 'president’s': 543,\n",
       " 'decision': 544,\n",
       " 'respect': 545,\n",
       " 'local': 546,\n",
       " 'jill': 547,\n",
       " 'control': 548,\n",
       " 'given': 549,\n",
       " 'comes': 550,\n",
       " 'knows': 551,\n",
       " 'else': 552,\n",
       " 'countries': 553,\n",
       " 'defend': 554,\n",
       " 'system': 555,\n",
       " 'provide': 556,\n",
       " 'choice': 557,\n",
       " 'voice': 558,\n",
       " 'create': 559,\n",
       " 'took': 560,\n",
       " 'class': 561,\n",
       " 'presidential': 562,\n",
       " 'ban': 563,\n",
       " 'used': 564,\n",
       " '3rd': 565,\n",
       " 'biggest': 566,\n",
       " 'having': 567,\n",
       " 'book': 568,\n",
       " 'reporters': 569,\n",
       " 'line': 570,\n",
       " 'choose': 571,\n",
       " '100': 572,\n",
       " 'meet': 573,\n",
       " 'debate': 574,\n",
       " 'lower': 575,\n",
       " 'thanks': 576,\n",
       " 'victory': 577,\n",
       " 'votes': 578,\n",
       " 'tell': 579,\n",
       " 'we’ve': 580,\n",
       " 'de': 581,\n",
       " 'low': 582,\n",
       " 'hit': 583,\n",
       " 'death': 584,\n",
       " 'there’s': 585,\n",
       " 'weeks': 586,\n",
       " 'thousands': 587,\n",
       " 'fully': 588,\n",
       " 'part': 589,\n",
       " 'politics': 590,\n",
       " 'hate': 591,\n",
       " 'opportunity': 592,\n",
       " 'anything': 593,\n",
       " 'mr': 594,\n",
       " 'trade': 595,\n",
       " 'nancy': 596,\n",
       " 'turn': 597,\n",
       " 'rally': 598,\n",
       " 'set': 599,\n",
       " 'south': 600,\n",
       " 'front': 601,\n",
       " 'loves': 602,\n",
       " 'such': 603,\n",
       " 'lamestream': 604,\n",
       " 'affordable': 605,\n",
       " 'speaking': 606,\n",
       " 'quickly': 607,\n",
       " 'listen': 608,\n",
       " \"that's\": 609,\n",
       " 'cares': 610,\n",
       " 'kentucky': 611,\n",
       " 'billion': 612,\n",
       " 'disaster': 613,\n",
       " '2020': 614,\n",
       " 'poll': 615,\n",
       " 'recovery': 616,\n",
       " 'responsibility': 617,\n",
       " \"we'll\": 618,\n",
       " 'actually': 619,\n",
       " 'seen': 620,\n",
       " 'brave': 621,\n",
       " \"don't\": 622,\n",
       " 'nevada': 623,\n",
       " 'judge': 624,\n",
       " 'won': 625,\n",
       " 'approval': 626,\n",
       " \"trump's\": 627,\n",
       " 'men': 628,\n",
       " 'paid': 629,\n",
       " 'badly': 630,\n",
       " 'allow': 631,\n",
       " 'start': 632,\n",
       " 'case': 633,\n",
       " 'strongly': 634,\n",
       " 'pre': 635,\n",
       " 'especially': 636,\n",
       " 'restore': 637,\n",
       " 'equal': 638,\n",
       " 'term': 639,\n",
       " 'global': 640,\n",
       " 'farmers': 641,\n",
       " 'cities': 642,\n",
       " 'values': 643,\n",
       " 'experts': 644,\n",
       " 'whether': 645,\n",
       " 'combat': 646,\n",
       " 'past': 647,\n",
       " 'makes': 648,\n",
       " 'freedom': 649,\n",
       " 'hear': 650,\n",
       " 'critical': 651,\n",
       " 'democratic': 652,\n",
       " 'mayor': 653,\n",
       " 'prayers': 654,\n",
       " 'loved': 655,\n",
       " 'conditions': 656,\n",
       " 'safely': 657,\n",
       " 'faith': 658,\n",
       " 'little': 659,\n",
       " 'fear': 660,\n",
       " 'less': 661,\n",
       " 'become': 662,\n",
       " 'peace': 663,\n",
       " 'yesterday': 664,\n",
       " '“the': 665,\n",
       " 'major': 666,\n",
       " 'demdebate': 667,\n",
       " 'each': 668,\n",
       " 'voted': 669,\n",
       " 'isn’t': 670,\n",
       " '9': 671,\n",
       " 'spread': 672,\n",
       " 'along': 673,\n",
       " 'courage': 674,\n",
       " '11': 675,\n",
       " 'report': 676,\n",
       " 'massive': 677,\n",
       " 'supports': 678,\n",
       " 'nearly': 679,\n",
       " 'team': 680,\n",
       " 'address': 681,\n",
       " 'taken': 682,\n",
       " 'speak': 683,\n",
       " 'powerful': 684,\n",
       " 'stake': 685,\n",
       " 'union': 686,\n",
       " 'voters': 687,\n",
       " 'equality': 688,\n",
       " 'month': 689,\n",
       " 'force': 690,\n",
       " 'virginia': 691,\n",
       " 'paycheck': 692,\n",
       " 'moving': 693,\n",
       " 'city': 694,\n",
       " 'based': 695,\n",
       " 'resources': 696,\n",
       " 'guard': 697,\n",
       " 'late': 698,\n",
       " 'sick': 699,\n",
       " 'lies': 700,\n",
       " 'continues': 701,\n",
       " 'overcome': 702,\n",
       " 'final': 703,\n",
       " 'gets': 704,\n",
       " 'almost': 705,\n",
       " 'further': 706,\n",
       " 'minnesota': 707,\n",
       " 'wins': 708,\n",
       " 'prices': 709,\n",
       " 'mask': 710,\n",
       " 'process': 711,\n",
       " 'duty': 712,\n",
       " 'wait': 713,\n",
       " 'truly': 714,\n",
       " 'jim': 715,\n",
       " 'protecting': 716,\n",
       " 'governors': 717,\n",
       " 'borders': 718,\n",
       " 'anarchists': 719,\n",
       " 'rating': 720,\n",
       " 'path': 721,\n",
       " 'ones': 722,\n",
       " 'wish': 723,\n",
       " 'existing': 724,\n",
       " 'spent': 725,\n",
       " 'vaccine': 726,\n",
       " 'obamacare': 727,\n",
       " 'asked': 728,\n",
       " 'school': 729,\n",
       " 'leading': 730,\n",
       " 'town': 731,\n",
       " 'california': 732,\n",
       " 'constitution': 733,\n",
       " 'medical': 734,\n",
       " 'agenda': 735,\n",
       " 'terrible': 736,\n",
       " 'beautiful': 737,\n",
       " 'leave': 738,\n",
       " 'built': 739,\n",
       " 'arizona': 740,\n",
       " 'partisan': 741,\n",
       " 'keeping': 742,\n",
       " 'wanted': 743,\n",
       " 'tuesday': 744,\n",
       " \"i've\": 745,\n",
       " 'guy': 746,\n",
       " 'went': 747,\n",
       " 'allowed': 748,\n",
       " '2a': 749,\n",
       " 'drug': 750,\n",
       " 'georgia': 751,\n",
       " 'young': 752,\n",
       " 'came': 753,\n",
       " \"you're\": 754,\n",
       " 'destroy': 755,\n",
       " 'ohio': 756,\n",
       " 'brought': 757,\n",
       " 'helped': 758,\n",
       " 'highest': 759,\n",
       " 'mark': 760,\n",
       " 'mcconnell': 761,\n",
       " 'committed': 762,\n",
       " 'tom': 763,\n",
       " 'ratings': 764,\n",
       " 'scam': 765,\n",
       " 'schumer': 766,\n",
       " 'legal': 767,\n",
       " 'behind': 768,\n",
       " 'la': 769,\n",
       " 'works': 770,\n",
       " '7': 771,\n",
       " 'helping': 772,\n",
       " 'citizens': 773,\n",
       " 'package': 774,\n",
       " 'nobody': 775,\n",
       " 'weak': 776,\n",
       " 'serious': 777,\n",
       " 'former': 778,\n",
       " 'problem': 779,\n",
       " 'funds': 780,\n",
       " 'ventilators': 781,\n",
       " 'officials': 782,\n",
       " 'foreign': 783,\n",
       " 'expand': 784,\n",
       " 'questions': 785,\n",
       " 'infrastructure': 786,\n",
       " 'wealthy': 787,\n",
       " 'attack': 788,\n",
       " 'dr': 789,\n",
       " 'bigger': 790,\n",
       " 'find': 791,\n",
       " 'couldn’t': 792,\n",
       " 'hold': 793,\n",
       " 'stage': 794,\n",
       " 'conversation': 795,\n",
       " 'essential': 796,\n",
       " 'c': 797,\n",
       " 'saved': 798,\n",
       " 'lines': 799,\n",
       " 'goes': 800,\n",
       " 'nomination': 801,\n",
       " 'joined': 802,\n",
       " 'elections': 803,\n",
       " 'speaker': 804,\n",
       " 'equipment': 805,\n",
       " 'facing': 806,\n",
       " 'move': 807,\n",
       " 'honored': 808,\n",
       " 'takes': 809,\n",
       " 'top': 810,\n",
       " '8': 811,\n",
       " 'meeting': 812,\n",
       " 'super': 813,\n",
       " 'we’ll': 814,\n",
       " 'd': 815,\n",
       " 'worse': 816,\n",
       " 'agree': 817,\n",
       " 'passing': 818,\n",
       " 'reform': 819,\n",
       " 'fraud': 820,\n",
       " 'members': 821,\n",
       " 'beginning': 822,\n",
       " 'ask': 823,\n",
       " 'agreement': 824,\n",
       " \"let's\": 825,\n",
       " 'rebuild': 826,\n",
       " 'told': 827,\n",
       " 'nation’s': 828,\n",
       " 'hardworking': 829,\n",
       " 'epidemic': 830,\n",
       " 'dignity': 831,\n",
       " 'today’s': 832,\n",
       " 'unite': 833,\n",
       " 'talk': 834,\n",
       " 'primary': 835,\n",
       " 'enjoy': 836,\n",
       " 'request': 837,\n",
       " 'smart': 838,\n",
       " 'rate': 839,\n",
       " 'biden’s': 840,\n",
       " 'portland': 841,\n",
       " 'joining': 842,\n",
       " 'simple': 843,\n",
       " 'racial': 844,\n",
       " 'god': 845,\n",
       " 'period': 846,\n",
       " 'food': 847,\n",
       " 'celebrate': 848,\n",
       " 'standing': 849,\n",
       " 'lose': 850,\n",
       " 'hall': 851,\n",
       " 'something': 852,\n",
       " 'means': 853,\n",
       " 'neighbors': 854,\n",
       " 'demconvention': 855,\n",
       " 'sanders': 856,\n",
       " 'heart': 857,\n",
       " 'whole': 858,\n",
       " 'worked': 859,\n",
       " 'human': 860,\n",
       " 'shot': 861,\n",
       " 'knew': 862,\n",
       " 'higher': 863,\n",
       " 'building': 864,\n",
       " 'george': 865,\n",
       " 'secretary': 866,\n",
       " 'west': 867,\n",
       " 'calling': 868,\n",
       " 'fighter': 869,\n",
       " 'dangerous': 870,\n",
       " 'winning': 871,\n",
       " 'thought': 872,\n",
       " '45': 873,\n",
       " 'congressional': 874,\n",
       " 'heading': 875,\n",
       " 'hampshire': 876,\n",
       " 'stories': 877,\n",
       " 'commitment': 878,\n",
       " 'return': 879,\n",
       " 'gave': 880,\n",
       " 'supporters': 881,\n",
       " 'market': 882,\n",
       " 'secure': 883,\n",
       " 'spoke': 884,\n",
       " 'check': 885,\n",
       " 'masks': 886,\n",
       " 'msdnc': 887,\n",
       " 'urgent': 888,\n",
       " '6': 889,\n",
       " 'died': 890,\n",
       " 'message': 891,\n",
       " 'hands': 892,\n",
       " 'watching': 893,\n",
       " 'division': 894,\n",
       " 'absentee': 895,\n",
       " 'asking': 896,\n",
       " 'character': 897,\n",
       " 'here’s': 898,\n",
       " 'serve': 899,\n",
       " 'saying': 900,\n",
       " 'cost': 901,\n",
       " 'failure': 902,\n",
       " 'forget': 903,\n",
       " 'steps': 904,\n",
       " '15': 905,\n",
       " '50': 906,\n",
       " 'starts': 907,\n",
       " 'policies': 908,\n",
       " 'happening': 909,\n",
       " 'later': 910,\n",
       " 'benefits': 911,\n",
       " 'companies': 912,\n",
       " 'caught': 913,\n",
       " 'happened': 914,\n",
       " 'signed': 915,\n",
       " 'democrats’': 916,\n",
       " 'special': 917,\n",
       " 'counted': 918,\n",
       " 'exactly': 919,\n",
       " 'share': 920,\n",
       " 'enemy': 921,\n",
       " 'sad': 922,\n",
       " 'point': 923,\n",
       " 'understand': 924,\n",
       " 'highly': 925,\n",
       " 'wow': 926,\n",
       " 'illegal': 927,\n",
       " \"won't\": 928,\n",
       " 'fights': 929,\n",
       " 'putting': 930,\n",
       " 'stock': 931,\n",
       " 'register': 932,\n",
       " 'starting': 933,\n",
       " 'what’s': 934,\n",
       " 'test': 935,\n",
       " 'march': 936,\n",
       " 'playing': 937,\n",
       " 'rigged': 938,\n",
       " 'harris': 939,\n",
       " 'effort': 940,\n",
       " 'bold': 941,\n",
       " 'rest': 942,\n",
       " 'y': 943,\n",
       " \"here's\": 944,\n",
       " 'himself': 945,\n",
       " 'different': 946,\n",
       " 'kids': 947,\n",
       " 'students': 948,\n",
       " 'talking': 949,\n",
       " 'defense': 950,\n",
       " 'zero': 951,\n",
       " 'closely': 952,\n",
       " 'released': 953,\n",
       " 'deaths': 954,\n",
       " 'unacceptable': 955,\n",
       " 'candidate': 956,\n",
       " 'aid': 957,\n",
       " 'easy': 958,\n",
       " 'information': 959,\n",
       " 'politician': 960,\n",
       " '2nd': 961,\n",
       " 'defendourdemocracy': 962,\n",
       " 'attacks': 963,\n",
       " '20': 964,\n",
       " 'chief': 965,\n",
       " 'staff': 966,\n",
       " 'vice': 967,\n",
       " 'example': 968,\n",
       " 'word': 969,\n",
       " 'strength': 970,\n",
       " 'pain': 971,\n",
       " 'says': 972,\n",
       " 'side': 973,\n",
       " 'answer': 974,\n",
       " 'successful': 975,\n",
       " 'name': 976,\n",
       " 'toward': 977,\n",
       " 'rather': 978,\n",
       " 'facts': 979,\n",
       " 'forced': 980,\n",
       " 'hospitals': 981,\n",
       " 'fantastic': 982,\n",
       " 'impact': 983,\n",
       " 'common': 984,\n",
       " 'struggling': 985,\n",
       " 'alone': 986,\n",
       " 'challenge': 987,\n",
       " 'count': 988,\n",
       " 'light': 989,\n",
       " 'lgbtq': 990,\n",
       " 'risk': 991,\n",
       " \"there's\": 992,\n",
       " 'led': 993,\n",
       " 'try': 994,\n",
       " 'reason': 995,\n",
       " 'despite': 996,\n",
       " 'chris': 997,\n",
       " 'assault': 998,\n",
       " 'purpose': 999,\n",
       " 'racism': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use the tokenizer to convert all texts in the training-set to lists of these tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tokens = tokenizer.texts_to_sequences(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_tokens = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding and Truncating Data\n",
    "\n",
    "The Recurrent Neural Network can take sequences of arbitrary length as input, but in order to use a whole batch of data, the sequences need to have the same length. There are two ways of achieving this: (A) Either we ensure that all sequences in the entire data-set have the same length, or (B) we write a custom data-generator that ensures the sequences have the same length within each batch.\n",
    "\n",
    "Solution (A) is simpler but if we use the length of the longest sequence in the data-set, then we are wasting a lot of memory. This is particularly important for larger data-sets.\n",
    "\n",
    "So in order to make a compromise, we will use a sequence-length that covers most sequences in the data-set, and we will then truncate longer sequences and pad shorter sequences.\n",
    "\n",
    "First we count the number of tokens in all the sequences in the data-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = [len(tokens) for tokens in x_train_tokens + x_test_tokens]\n",
    "num_tokens = np.array(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19, 31, 45, ..., 41, 42, 21])"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.133006650332515"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "max_tokens = int(max_tokens)\n",
    "max_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9994166374985416"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(num_tokens < max_tokens) / len(num_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is where data is padded.\n",
    "\n",
    "When padding or truncating the sequences that have a different length, we need to determine if we want to do this padding or truncating 'pre' or 'post'. If a sequence is truncated, it means that a part of the sequence is simply thrown away. If a sequence is padded, it means that zeros are added to the sequence.\n",
    "\n",
    "So the choice of 'pre' or 'post' can be important because it determines whether we throw away the first or last part of a sequence when truncating, and it determines whether we add zeros to the beginning or end of the sequence when padding. This may confuse the Recurrent Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = 'pre'\n",
    "x_train_pad = pad_sequences(x_train_tokens, maxlen=max_tokens,\n",
    "                            padding=pad, truncating=pad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_pad = pad_sequences(x_test_tokens, maxlen=max_tokens,\n",
    "                           padding=pad, truncating=pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ..., 1195,  605,  110],\n",
       "       [   0,    0,    0, ..., 1141,  520, 2136],\n",
       "       [   0,    0,    0, ...,  432,    4,  118],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    1,   44,   34],\n",
       "       [   0,    0,    0, ...,   10, 3564,  711],\n",
       "       [   0,    0,    0, ...,  593,   80,  135]])"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6428, 57)"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2143, 57)"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = tokenizer.word_index\n",
    "inverse_map = dict(zip(idx.values(), idx.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_string(tokens):\n",
    "    # Map from tokens back to words.\n",
    "    words = [inverse_map[token] for token in tokens if token != 0]\n",
    "    \n",
    "    # Concatenate all words.\n",
    "    text = \" \".join(words)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' to the millions of hindus, jains, sikhs, and buddhists celebrating the festival of lights,  and i send our best wishes for a #happydiwali. may your new year be filled with hope, happiness, and prosperity. sal mubarak.\\n'"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i issued the following statement with on the urgent need to replenish the paycheck protection program there is no excuse for a lack of urgency american jobs are literally at stake'"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_to_string(x_train_tokens[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Recurrent Neural Network\n",
    "\n",
    "We are now ready to create the Recurrent Neural Network (RNN). We will use the Keras API for this because of its simplicity. See Tutorial #03-C for a tutorial on Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedding-layer also needs to know the number of words in the vocabulary (`num_words`) and the length of the padded token-sequences (`max_tokens`). We also give this layer a name because we need to retrieve its weights further below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Embedding(input_dim=num_words,\n",
    "                    output_dim=embedding_size,\n",
    "                    input_length=max_tokens,\n",
    "                    name='layer_embedding'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now add the first Gated Recurrent Unit (GRU) to the network. This will have 16 outputs. Because we will add a second GRU after this one, we need to return sequences of data because the next GRU expects sequences as its input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(GRU(units=16, return_sequences=True))\n",
    "model.add(GRU(units=8, return_sequences=True))\n",
    "model.add(GRU(units=4))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = Adam(lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer_embedding (Embedding)  (None, 57, 8)             80000     \n",
      "_________________________________________________________________\n",
      "gru_22 (GRU)                 (None, 57, 16)            1200      \n",
      "_________________________________________________________________\n",
      "gru_23 (GRU)                 (None, 57, 8)             600       \n",
      "_________________________________________________________________\n",
      "gru_24 (GRU)                 (None, 4)                 156       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 81,961\n",
      "Trainable params: 81,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Recurrent Neural Network\n",
    "\n",
    "We can now train the model. Note that we are using the data-set with the padded sequences. We use 5% of the training-set as a small validation-set, so we have a rough idea whether the model is generalizing well or if it is perhaps over-fitting to the training-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6106 samples, validate on 322 samples\n",
      "Epoch 1/3\n",
      "6106/6106 [==============================] - 14s 2ms/sample - loss: 0.0264 - accuracy: 0.9959 - val_loss: 0.3046 - val_accuracy: 0.9224\n",
      "Epoch 2/3\n",
      "6106/6106 [==============================] - 14s 2ms/sample - loss: 0.0196 - accuracy: 0.9977 - val_loss: 0.3230 - val_accuracy: 0.9130\n",
      "Epoch 3/3\n",
      "6106/6106 [==============================] - 15s 2ms/sample - loss: 0.0187 - accuracy: 0.9971 - val_loss: 0.3552 - val_accuracy: 0.9037\n",
      "Wall time: 42.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d525a4d488>"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(x_train_pad, y_train,\n",
    "          validation_split=0.05, epochs=3, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance on Test-Set\n",
    "\n",
    "Now that the model has been trained we can calculate its classification accuracy on the test-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2143/2143 - 5s - loss: 0.3051 - accuracy: 0.9169\n",
      "Normal Neural Network - Loss: 0.30507836667486177, Accuracy: 0.916938841342926\n",
      "Wall time: 4.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# result = model.evaluate(x_test_pad, y_test)\n",
    "model_loss, model_accuracy = model.evaluate(\n",
    "    x_test_pad, y_test, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model1119-2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OtherTest the model for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = model.predict(x=x_test_pad[0:1000])\n",
    "y_pred = y_pred.T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_pred = np.array([1.0 if p>0.5 else 0.0 for p in y_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_true = np.array(y_test[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect = np.where(cls_pred != cls_true)\n",
    "incorrect = incorrect[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = incorrect[0]\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' our country can’t afford a second epidemic of frivolous lawsuits while we fight the covid-19 pandemic. the next relief package should focus on four things: jobs, healthcare, kids in school, and liability protections for those helping us fight the coronavirus.  '"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = X_test.to_list()[idx]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94515264"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_true[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biden  tweet\n",
    "text1 = 'It’s not enough to praise our essential workers — we have to protect and pay them.'.lower()\n",
    "text2 = 'The workers on the frontlines of this pandemic are making extraordinary sacrifices every single day. They deserve leaders who will listen and work as hard for them as they are for their communities. As president, that’s exactly what I’ll do.'\n",
    "#trump tweet\n",
    "text3 = 'Hope that all House Republicans will vote against Crazy Nancy Pelosiï War Powers Resolution'\n",
    "text4 = 'PRESIDENTIAL HARASSMENT!'\n",
    "text5 = 'IRAN WILL NEVER HAVE A NUCLEAR WEAPON!'\n",
    "text6 = 'The Impeachment Hoax'\n",
    "text7 = 'Congress &amp; the President should not be wasting their time and energy on a continuation of the totally partisan Impeachment Hoax when we have so many important matters pending. 196 to ZERO was the Republican House vote'\n",
    "text8 = 'These Media Posts will serve as notification to the United States Congress that should Iran strike any U.S. person or target'\n",
    "texts = [text1, text2, text3, text4, text5, text6, text7, text8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['it’s not enough to praise our essential workers — we have to protect and pay them.', 'the workers on the frontlines of this pandemic are making extraordinary sacrifices every single day. they deserve leaders who will listen and work as hard for them as they are for their communities. as president, that’s exactly what i’ll do.', 'hope that all house republicans will vote against crazy nancy pelosiï war powers resolution', 'presidential harassment!', 'iran will never have a nuclear weapon!', 'the impeachment hoax', 'congress &amp; the president should not be wasting their time and energy on a continuation of the totally partisan impeachment hoax when we have so many important matters pending. 196 to zero was the republican house vote', 'these media posts will serve as notification to the united states congress that should iran strike any u.s. person or target']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(texts)):\n",
    "    texts[i] = texts[i].lower()\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 57)"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "tokens_pad = pad_sequences(tokens, maxlen=max_tokens,\n",
    "                           padding=pad, truncating=pad)\n",
    "tokens_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9928597 ],\n",
       "       [0.9928119 ],\n",
       "       [0.00724876],\n",
       "       [0.01900795],\n",
       "       [0.03351384],\n",
       "       [0.03952959],\n",
       "       [0.00930074],\n",
       "       [0.00776094]], dtype=float32)"
      ]
     },
     "execution_count": 558,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(tokens_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
